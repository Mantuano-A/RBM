{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f97d8643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script per analizzare errori / grafici\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib . pyplot as plt\n",
    "from scipy . stats import truncnorm # gaussiana andard troncata\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from termcolor import colored\n",
    "from threading import *\n",
    "import progressbar\n",
    "\n",
    "def sigma (x):\n",
    "    return 1/(1+ np.exp (- x))\n",
    "\n",
    "def dsigmaapprox (x ):\n",
    "    return x *(1 - x)\n",
    "\n",
    "def gaussiana_troncata ( media =0 , varianza =1 , a =0 , b=10) :\n",
    "    return truncnorm ((a - media )/ varianza , (b - media )/varianza , loc = media , scale = varianza )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af3a3754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-48:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\CASA-PC\\anaconda3\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"<ipython-input-40-08be1cc61d16>\", line 35, in run\n",
      "TypeError: 'module' object is not callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
      "0          5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "1          0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "2          4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "3          1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "4          9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
      "59995      8    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "59996      3    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "59997      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "59998      6    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "59999      8    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "\n",
      "       28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
      "0          0      0      0      0      0      0      0      0  \n",
      "1          0      0      0      0      0      0      0      0  \n",
      "2          0      0      0      0      0      0      0      0  \n",
      "3          0      0      0      0      0      0      0      0  \n",
      "4          0      0      0      0      0      0      0      0  \n",
      "...      ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "59995      0      0      0      0      0      0      0      0  \n",
      "59996      0      0      0      0      0      0      0      0  \n",
      "59997      0      0      0      0      0      0      0      0  \n",
      "59998      0      0      0      0      0      0      0      0  \n",
      "59999      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[60000 rows x 785 columns]\n",
      "\n",
      "Processo di caricamento e processamento dei dati di training completato .\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-49:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\CASA-PC\\anaconda3\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"<ipython-input-40-08be1cc61d16>\", line 41, in run\n",
      "TypeError: 'module' object is not callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
      "0         7    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "1         2    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "2         1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "3         0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "4         4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
      "9995      2    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "9996      3    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "9997      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "9998      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "9999      6    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "\n",
      "      28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
      "0         0      0      0      0      0      0      0      0  \n",
      "1         0      0      0      0      0      0      0      0  \n",
      "2         0      0      0      0      0      0      0      0  \n",
      "3         0      0      0      0      0      0      0      0  \n",
      "4         0      0      0      0      0      0      0      0  \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "9995      0      0      0      0      0      0      0      0  \n",
      "9996      0      0      0      0      0      0      0      0  \n",
      "9997      0      0      0      0      0      0      0      0  \n",
      "9998      0      0      0      0      0      0      0      0  \n",
      "9999      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[10000 rows x 785 columns]\n",
      "\n",
      "Processo di caricamento e processamento dei dati di test completato .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# *****************************************\n",
    "# PREPROCESSAMENTO DATI DI TRAINING e TEST\n",
    "dimensione_immagine = 28 # immaginte 28 x 28\n",
    "numero_etichette = 10 # numero delle cifre 0 ,1 ,... ,9\n",
    "pixel_immagine = dimensione_immagine * dimensione_immagine\n",
    "# 784 ~ numero di colonne del test_data + 1 che e' la colonna del label\n",
    "\n",
    "\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "class CaricamentoTrain ( Thread ):\n",
    "    def run ( self ): \n",
    "        global data_path\n",
    "        global train_data\n",
    "        train_data1 = pd.read_csv( \"mnist_train.csv\",delimiter =\",\")\n",
    "        train_data.append( train_data1 )\n",
    "        train_data = train_data[0]\n",
    "        print(train_data)\n",
    "        return train_data    \n",
    "\n",
    "class CaricamentoTest ( Thread ):\n",
    "    def run ( self ):\n",
    "        global data_path\n",
    "        global test_data\n",
    "        test_data1 = pd.read_csv( \"mnist_test.csv\", delimiter =\",\")\n",
    "        test_data.append( test_data1 )\n",
    "        test_data = test_data[0]\n",
    "        print(test_data)\n",
    "        return test_data\n",
    "\n",
    "class BarraTrain ( Thread ):\n",
    "    def run ( self ):\n",
    "        widgets =['[', progressbar.FileTransferSpeed() , ']',progressbar.Bar () ,'(', progressbar.Percentage () , ') ','(', progressbar.ETA () , ')',]\n",
    "        for i in progressbar.progressbar ( range (200) , widgets = widgets , prefix =\"Caricamento dati di training.\\t\"):\n",
    "            time.sleep (0.1)\n",
    "\n",
    "class BarraTest ( Thread ):\n",
    "     def run ( self ):\n",
    "        widgets =[ ' [', progressbar.FileTransferSpeed () , '] ',progressbar.Bar () ,' (', progressbar.Percentage () , ') ','(', progressbar.ETA () , ')',]\n",
    "        for i in progressbar.progressbar ( range (100) , widgets = widgets ,prefix =\"Caricamento dati di test.\\t\"):\n",
    "            time.sleep (0.1)\n",
    "\n",
    "t1 = CaricamentoTrain()\n",
    "t3 = CaricamentoTest()\n",
    "t2 = BarraTrain()\n",
    "t4 = BarraTest()\n",
    "t1.start()\n",
    "time.sleep(0.01)\n",
    "t2.start()\n",
    "t1.join()\n",
    "t2.join()\n",
    "print (\"\\nProcesso di caricamento e processamento dei dati di training completato .\\n\", end ='\\n')\n",
    "time.sleep(1)\n",
    "t3.start()\n",
    "time.sleep(0.01)\n",
    "t4.start()\n",
    "t3.join()\n",
    "t4.join()\n",
    "print (\"\\nProcesso di caricamento e processamento dei dati di test completato .\\n\", end ='\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9a6f758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0         7    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1         2    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2         1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3         0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4         4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
       "9995      2    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "9996      3    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "9997      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "9998      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "9999      6    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "      28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0         0      0      0      0      0      0      0      0  \n",
       "1         0      0      0      0      0      0      0      0  \n",
       "2         0      0      0      0      0      0      0      0  \n",
       "3         0      0      0      0      0      0      0      0  \n",
       "4         0      0      0      0      0      0      0      0  \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "9995      0      0      0      0      0      0      0      0  \n",
       "9996      0      0      0      0      0      0      0      0  \n",
       "9997      0      0      0      0      0      0      0      0  \n",
       "9998      0      0      0      0      0      0      0      0  \n",
       "9999      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[10000 rows x 785 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2488868e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0., 116., 125., 171., 255., 255.,\n",
       "       150.,  93.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       169., 253., 253., 253., 253., 253., 253., 218.,  30.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0., 169., 253., 253., 253., 213., 142.,\n",
       "       176., 253., 253., 122.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  52.,\n",
       "       250., 253., 210.,  32.,  12.,   0.,   6., 206., 253., 140.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  77., 251., 210.,  25.,   0.,   0.,\n",
       "         0., 122., 248., 253.,  65.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  31.,  18.,   0.,   0.,   0.,   0., 209., 253., 253.,  65.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0., 117., 247., 253., 198.,  10.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,  76., 247., 253., 231.,  63.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0., 128., 253., 253., 144.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0., 176., 246., 253., 159.,  12.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        25., 234., 253., 233.,  35.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0., 198., 253., 253., 141.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        78., 248., 253., 189.,  12.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  19., 200., 253., 253., 141.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       134., 253., 253., 173.,  12.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0., 248., 253., 253.,  25.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0., 248., 253., 253.,  43.,  20.,  20.,  20.,  20.,   5.,   0.,\n",
       "         5.,  20.,  20.,  37., 150., 150., 150., 147.,  10.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 248., 253., 253., 253.,\n",
       "       253., 253., 253., 253., 168., 143., 166., 253., 253., 253., 253.,\n",
       "       253., 253., 253., 123.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0., 174., 253., 253., 253., 253., 253., 253., 253., 253.,\n",
       "       253., 253., 253., 249., 247., 247., 169., 117., 117.,  57.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 118., 123.,\n",
       "       123., 123., 166., 253., 253., 253., 155., 123., 123.,  41.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.asfarray(test_data)\n",
    "x[1, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "52317376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 116., 125., 171., 255.,\n",
       "       255., 150.,  93.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0., 169., 253., 253., 253., 253., 253., 253., 218.,  30.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0., 169., 253., 253., 253., 213.,\n",
       "       142., 176., 253., 253., 122.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        52., 250., 253., 210.,  32.,  12.,   0.,   6., 206., 253., 140.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,  77., 251., 210.,  25.,   0.,\n",
       "         0.,   0., 122., 248., 253.,  65.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  31.,  18.,   0.,   0.,   0.,   0., 209., 253., 253.,\n",
       "        65.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0., 117., 247., 253., 198.,  10.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,  76., 247., 253., 231.,\n",
       "        63.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0., 128., 253., 253., 144.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 176., 246., 253., 159.,\n",
       "        12.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  25., 234., 253., 233.,  35.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 198., 253., 253., 141.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  78., 248., 253., 189.,  12.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,  19., 200., 253., 253., 141.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0., 134., 253., 253., 173.,  12.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 248., 253., 253.,  25.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0., 248., 253., 253.,  43.,  20.,  20.,  20.,  20.,   5.,\n",
       "         0.,   5.,  20.,  20.,  37., 150., 150., 150., 147.,  10.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 248., 253., 253.,\n",
       "       253., 253., 253., 253., 253., 168., 143., 166., 253., 253., 253.,\n",
       "       253., 253., 253., 253., 123.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0., 174., 253., 253., 253., 253., 253., 253., 253.,\n",
       "       253., 253., 253., 253., 249., 247., 247., 169., 117., 117.,  57.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 118.,\n",
       "       123., 123., 123., 166., 253., 253., 253., 155., 123., 123.,  41.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0f0b1f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       7\n",
       "1       2\n",
       "2       1\n",
       "3       0\n",
       "4       4\n",
       "       ..\n",
       "9995    2\n",
       "9996    3\n",
       "9997    4\n",
       "9998    5\n",
       "9999    6\n",
       "Name: label, Length: 10000, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ecc5ab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "scala = 0.99 / 255 #i codici per pixel grigi vannoda 0 a 255\n",
    "immagini_training = np.asfarray ( train_data )[: , 1:] *scala + 0.01\n",
    "immagini_test = np.asfarray ( test_data )[: , 1:] *scala + 0.01\n",
    "# prendiamo valori nella matrice tra (0 ,1] -> [0.1 ,1]\n",
    "#e normalizziamo\n",
    "label_training = np.asfarray ( train_data )[: , :1]\n",
    "label_test = np.asfarray ( test_data )[: , :1]\n",
    "\n",
    "# associamo ad ogni cifra un vettore della basecanonica\n",
    "v= np.arange (10)\n",
    "for etichetta in range (10) :\n",
    "    ei =( v == etichetta ). astype ( np.int )\n",
    " # print (\" Etichetta \", etichetta , \" vettore \", ei)\n",
    "\n",
    "# facciamo la stessa cosa sul vettore dei label memorizzato prima e\n",
    "# togliamo sostiuiamo gli 0 - >0.01\n",
    "tmp = np.arange ( numero_etichette )\n",
    "etichette_training = ( tmp == label_training ).astype( np.float )\n",
    "etichette_test =( tmp == label_test ).astype( np.float )\n",
    "\n",
    "etichette_training [ etichette_training ==0]=0.01\n",
    "etichette_test [ etichette_test ==0]=0.01\n",
    "\n",
    "etichette_training [ etichette_training ==1]=1\n",
    "etichette_test [ etichette_test ==1]=1\n",
    "\n",
    "# Creiamo la classe della rete di richiamo\n",
    "# Definiamo gli estremi di troncamento e i paramentri\n",
    "#di standardizzazione della gaussiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ea2953c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------00----\n",
      "--------------------0000----\n",
      "----------------00000000----\n",
      "-------------00000000000----\n",
      "----------000000000000------\n",
      "-------000000000------------\n",
      "----0000000000--------------\n",
      "----000000------------------\n",
      "----00----------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = 2\n",
    "\n",
    "due = x[ind, 1:]\n",
    "due = [due[i::28] for i in range(28)]\n",
    "\n",
    "for i in range(28):\n",
    "    for j in range(28):\n",
    "        if j == 27:\n",
    "            if due[i][j]==0:\n",
    "                print(\"-\")\n",
    "            else: print(0)\n",
    "        else:    \n",
    "            if due[i][j]==0:\n",
    "                print(\"-\", end = '')\n",
    "            else: print(0, end = '')\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from matplotlib import pyplot\n",
    "\n",
    "pyplot.imshow(due, cmap=pyplot.get_cmap('gray'))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9b9b062e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('mnist_test.csv', one_hot = True)\n",
    "first_image = mnist.test.images[ind]\n",
    "first_image = np.array(first_image, dtype='float')\n",
    "pixels = first_image.reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fcdbced2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [due[i::28] for i in range(28)]\n",
    "len(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "596c6f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(arr, size):\n",
    "    arrs = []\n",
    "    while len(arr) > size:\n",
    "        pice = arr[:size]\n",
    "        arrs.append(pice)\n",
    "        arr   = arr[size:]\n",
    "        arrs.append(arr)\n",
    "    return arrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "357587f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-65cf85273153>, line 222)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-19-65cf85273153>\"\u001b[1;36m, line \u001b[1;32m222\u001b[0m\n\u001b[1;33m    MacchinaBoltzmann = BM ( nodi_visibili =pixel_immagine ,nodi_nascosti =Arr_Nodi_Nascosti [ i],nodi_output =10 ,tasso_apprendimento =Arr_Tasso_Apprendimento [j ])ListaBM.append ( MacchinaBoltzmann )\u001b[0m\n\u001b[1;37m                                                                                                                                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# **********************************\n",
    "# CREAZIONE CLASSE RETE NEURONALE\n",
    "\n",
    "class BM :\n",
    "    def __init__ ( self , nodi_visibili , nodi_nascosti , nodi_output , tasso_apprendimento ) :\n",
    "        self.nodi_visibili = nodi_visibili\n",
    "        self.nodi_nascosti = nodi_nascosti\n",
    "        self.nodi_output = nodi_output\n",
    "        self.tasso_apprendimento = tasso_apprendimento\n",
    "\n",
    "        self.CreaMatricePesi()\n",
    "        self.LogErr =0\n",
    "        self.MSE =0\n",
    "\n",
    "    def CreaMatricePesi ( self ):\n",
    " # inizializziamo la matrice dei pesi usando la distribuzione\n",
    " # normale definita sopra [ cfr.Masters Timothy ]\n",
    "        var1 =1 / np.sqrt( self.nodi_visibili )\n",
    "        M = gaussiana_troncata (0 ,1 , - var1 , var1 )\n",
    "        self.MatriceInputHidden = M.rvs(( self.nodi_nascosti, self.nodi_visibili ))\n",
    "        var2 =1/ np.sqrt ( self.nodi_nascosti )\n",
    "        M = gaussiana_troncata (0 ,1 , - var2 , var2 )\n",
    "        self.MatriceHiddenOutput = M. rvs((self.nodi_output, self.nodi_nascosti ))\n",
    "\n",
    " # funzione di training applichiamo usiamo un algoritmo di backpropagation\n",
    " # una discesa del gradiente ( con approssimazionedella derivata ). NO BIAS\n",
    "          \n",
    "    def Allenamento ( self , vettore_input ,vettore_obbiettivo ):\n",
    "        vettore_input = np.array ( vettore_input , ndmin=2).T\n",
    "        vettore_obbiettivo = np.array (vettore_obbiettivo , ndmin =2).T\n",
    " # calcolo le probabilita ' di attivaizione dei neuronivisibili\n",
    "        output_v1 = np.dot( self.MatriceInputHidden , vettore_input )\n",
    "        output_hid = sigma( output_v1 )\n",
    " # calcolo le probabilita ' di attivazione dei vettorihidden\n",
    "        output_v2 = np.dot( self.MatriceHiddenOutput ,output_hid )\n",
    "        output = sigma( output_v2 )\n",
    " # errore strato visibile\n",
    "        errore = vettore_obbiettivo - output # calcolo errore\n",
    " # errore quadratico medio e cross entropy\n",
    "        uno = np.array ([1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1])\n",
    "        self.MSE =(1/10) *((( output - vettore_obbiettivo) **2).sum () )\n",
    "        self.LogErr = -( vettore_obbiettivo * np.log (output ) +( uno - vettore_obbiettivo )* np.log ( uno - output ) ). sum ()\n",
    " # aggiorniamo i pesi MHO\n",
    "        delta = errore * dsigmaapprox ( output )\n",
    "        aggiornamento = self.tasso_apprendimento * np.dot ( delta , output_hid .T)\n",
    "        self.MatriceHiddenOutput += aggiornamento\n",
    " # errore strato nascosto\n",
    "        errore_hidden = np.dot( self.MatriceHiddenOutput .T , errore )\n",
    " # aggiornamnento pesi MIH\n",
    "        delta1 = errore_hidden * dsigmaapprox ( output_hid)\n",
    "        self.MatriceInputHidden += self.tasso_apprendimento * np.dot ( delta1 , vettore_input.T)\n",
    "\n",
    "    def Pensa ( self , vettore_input ):\n",
    "        vettore_input = np.array ( vettore_input ).T\n",
    "        vettore_out = sigma ( np.dot ( self.MatriceInputHidden , vettore_input ) )\n",
    "        vettore_out = sigma ( np.dot ( self.MatriceHiddenOutput , vettore_out ))\n",
    "    return vettore_out\n",
    "\n",
    " # *** FUNZIONI DI ANALLISI E VALIDAZIONE ***\n",
    " # Calcoliamo la matrice di confusione , che da ' unastima della\n",
    " # accuratezza del processo di training ericonoscimento .\n",
    " # Gli elementi sulla diagonale sono il numero deipattern\n",
    " # giustamente riconosciuti e collegati al labelgiusto .\n",
    " # Quelli extradiagonali sono quelli non correttamenteassociati\n",
    "\n",
    "    def MatricediConfusione ( self , dati , etichetta ):\n",
    "        MatConf = np.zeros ((10 ,10) , dtype =int)\n",
    "        for i in range ( len ( dati )) :\n",
    "            risposta = self.Pensa ( dati [i ])\n",
    "            risposta_max = risposta.argmax () # indice del max sulla riga\n",
    "            task = etichetta [i ][0]\n",
    "            MatConf [ risposta_max , int ( task )] += 1\n",
    "        return MatConf\n",
    "\n",
    " # sulla diagonale vi sono il numero delle predizioni corrette\n",
    "\n",
    "    def CalcoloPrecisione ( self , etichetta , MatConf ): \n",
    "        colonna = MatConf [: , etichetta ] # prendo la colonna riferita al label\n",
    "        return MatConf [ etichetta , etichetta ]/ colonna.sum ()\n",
    "          \n",
    "#La precisione e' la percentuale delle previsionipositive\n",
    "# corrette sul totale delle previsioni positive delmodello .\n",
    " # percisione_i := \\ frac {M_{i,i }}{\\ sum_j M_{j,i}}\n",
    " # cioe ' l'elemento i- esimo della diagonale fratto lasomma\n",
    " # degli elementi della colonna i- esima\n",
    "\n",
    "    def CaloloRichiamo ( self , etichetta , MatConf ):\n",
    "        riga = MatConf [ etichetta ,:] # prendo la riga riferita al label\n",
    "        return MatConf [ etichetta , etichetta ]/ riga.sum()\n",
    " \n",
    " #Il richiamo e' la percentuale delle previsionipositive\n",
    " # corrette sul totale delle istanze positive .\n",
    " # richiamo_i := \\ frac {M_{i,i }}{\\ sum_j M_{ij }}\n",
    " # cioe ' e' l'elemento i- esimo della diagonale frattola somma\n",
    " # degli elementi della riga i- esima\n",
    "\n",
    " # Analizziamo i risultati e vediamo quale istanzesono corrette\n",
    " #e quali sono sbagliate , per avere una stima dell ' errore compuito .\n",
    "    def Analisi ( self , dati , etichetta ) :\n",
    "        giusto =0\n",
    "        sbagliato =0\n",
    "        for i in range ( len ( dati )) :\n",
    "            risposta = self.Pensa ( dati [i ]) # processo il pattern i- esimo\n",
    "            risposta_max = risposta.argmax ()\n",
    " # determino l'inidice dell 'elemento di modulo max\n",
    " #e controllo se per caso non sta sulla diagonale\n",
    " #in quel caso sara ' corretto , altrimenti sara 'sbagliato\n",
    "            if risposta_max == etichetta [i ]:\n",
    "                giusto += 1\n",
    "            else :\n",
    "                sbagliato += 1\n",
    "        return giusto , sbagliato\n",
    "\n",
    "    def Accuratezza ( self , MatConf ):\n",
    "        somma_diagonale = MatConf.trace ()\n",
    "        somma_totale = MatConf.sum ()\n",
    "        return somma_diagonale / somma_totale\n",
    " # facciamo il rapporto tra la traccia della matrice ela somma di tutti\n",
    " # gli elementi : infatti sulla diagonale vi sono leistanze correttamente\n",
    " # riconosciute e abbianate .\n",
    "\n",
    " # ***********************************\n",
    " # CREAZIONE CLASSE della RETE\n",
    "Arr_Nodi_Nascosti =20 +20* np.array ( range (5) ) # numerodi neuroni nascosti\n",
    "Arr_Tasso_Apprendimento = 0.1 + 0.2* np.array ( range(5) )\n",
    "\n",
    " # creo una lista di oggetti in cui vi sono le varie\n",
    " # classi BM con diversi valori dei parametri\n",
    "\n",
    "ListaBM =[]\n",
    "for i in range (5) :\n",
    "    for j in range (5) :\n",
    "        MacchinaBoltzmann = BM ( nodi_visibili =pixel_immagine ,nodi_nascosti =Arr_Nodi_Nascosti [ i],nodi_output =10 ,tasso_apprendimento =Arr_Tasso_Apprendimento [j ])ListaBM.append ( MacchinaBoltzmann )\n",
    "\n",
    " # ***************************************\n",
    " # Trasformo la lista in una matrice 5x5\n",
    " # per poterci lavorare sopra\n",
    "          \n",
    "L= ListaBM\n",
    "L= np.asarray ( ListaBM )\n",
    "L= np.split (L ,5 , axis =0)\n",
    "L1 = np.stack (L)\n",
    "\n",
    "# raccolgo i valori delgi errori a processo\n",
    "#di allenamento compleato\n",
    "MatErr = np.zeros ((5 ,5) )\n",
    "MatLogErr = np.zeros ((5 ,5) )\n",
    "\n",
    " # raccolgo i valori delgi errori durante il processo\n",
    "MatIterateMSE =[]\n",
    "MatIterateLogErr =[]\n",
    "\n",
    "AssembleMatriceConfusione =[] # Lista contentente Mat .Conf .\n",
    "MatriceAccuratezze = np.zeros ((5 ,5) ) # Matrice delle accuratezze\n",
    "\n",
    "\n",
    "for i in range (5) :\n",
    "    for j in range (5) :\n",
    "        Macchina = L1 [i ][ j]\n",
    "        for k in range ( len ( immagini_training )):\n",
    "            Macchina.Allenamento ( immagini_training [k], etichette_training [k ])\n",
    "            MatErr [ i ][ j] = Macchina.MSE\n",
    "            MatLogErr [ i ][ j] = Macchina.LogErr\n",
    "            MC = Macchina.MatricediConfusione (immagini_training , label_training )\n",
    "            AssembleMatriceConfusione.append ( MC )\n",
    "            MatriceAccuratezze [ i ][ j] = Macchina.Accuratezza ( MC )\n",
    "\n",
    "AssembleMC = AssembleMatriceConfusione\n",
    "AssembleMC = np.asarray ( AssembleMC )\n",
    "AssembleMC = np.split ( AssembleMC ,5 , axis =0)\n",
    "AssembleMC = np.stack ( AssembleMC )\n",
    "\n",
    " # ##########################\n",
    " # TEST RETE\n",
    "NumTest =20\n",
    "Matrice_MSE_TEST =[]\n",
    "\n",
    "for i in range (5) :\n",
    "    for j in range (5) :\n",
    "        BM = L1 [ i ][ j]\n",
    "        Vett_MSE_Test =[]\n",
    "        for k in range ( NumTest ): # faccio i primi 50 test per ogni par .\n",
    "            out = BM.Pensa ( immagini_test [k ])\n",
    "            err = (1/10) *((( out - etichette_test [ k ])**2).sum () )\n",
    "            Vett_MSE_Test.append ( err ) # vett 1 xrange\n",
    "            Matrice_MSE_TEST.append ( np.asarray (\n",
    "    Vett_MSE_Test , dtype = float ))\n",
    "\n",
    "Matrice_MSE_TEST = np.asarray ( Matrice_MSE_TEST )\n",
    "Matrice_MSE_TEST = np.split ( Matrice_MSE_TEST ,5 , axis =0)\n",
    "Matrice_MSE_TEST = np.stack ( Matrice_MSE_TEST )\n",
    "\n",
    "alpha =int( input (\" Scegli un valore per il tasso diapprendimento \\ ntra {1 ,3 ,5 ,7 ,9}: \"))\n",
    "N= int ( input (\" Scegli il numero dei neuroni nascosti \\ntra {20 ,40 ,60 ,80 ,100}: \"))\n",
    "\n",
    "if alpha == 1:\n",
    "    alpha1 = 0\n",
    "elif alpha == 3:\n",
    "    alpha1 = 1\n",
    "elif alpha == 5:\n",
    "    alpha1 = 2\n",
    "elif alpha == 7:\n",
    "    alpha1 = 3\n",
    "elif alpha == 9:\n",
    "    alpha1 = 4\n",
    "\n",
    "if N == 20:\n",
    "    N1 = 0\n",
    "                    \n",
    "elif N == 40:\n",
    "    N1 = 1\n",
    "elif N == 60:\n",
    "    N1 = 2\n",
    "elif N == 80:\n",
    "    N1 = 3\n",
    "elif N == 100:\n",
    "    N1 = 4\n",
    "\n",
    "# ######################################\n",
    "# VISUALIZZAZIONE DEI DATI CALCOLATI\n",
    "\n",
    "fig1 , ax1 = plt.subplots ()\n",
    "for i in range (5) :\n",
    "    ax1.plot ( MatErr [i], label =\"N=%s\" % (( i +1) *20) ,marker ='o')\n",
    "plt.xticks ( np.arange (0 ,5 , step =1) ,\n",
    "labels = np.array ([0.1 ,0.3 ,0.5 ,0.7 ,0.9]) )\n",
    "plt.title (r'Plotting $MSE_ {\\ alpha }$', fontsize ='large ', fontweight ='bold ')\n",
    "plt.xlabel (r'Valori di $\\ alpha$ - Tasso di apprendimento ', fontsize ='large ')\n",
    "plt.ylabel (r'$MSE_ {\\ alpha }$', fontsize ='large ')\n",
    "plt.legend ()\n",
    "\n",
    "MatErr2 = MatErr .T\n",
    "fig2 , ax2 = plt.subplots ()\n",
    "for i in range (5) :\n",
    "ax2.plot ( MatErr2 [i], label =r'$\\ alpha$ =%.2 g' % ((2* i +1) *0.1) , marker ='*')\n",
    "plt.xticks ( np.arange (0 ,5 , step =1) ,\n",
    "labels = np.array ([20 ,40 ,60 ,80 ,100]) )\n",
    "plt.title (r'Plotting $MSE_N$ ', fontsize ='large ',fontweight ='bold ')\n",
    "plt.xlabel (r'$N$ - Numero di neuroni nascosti ', fontsize ='large ')\n",
    "plt.ylabel (r'$MSE_N$ ', fontsize ='large ')\n",
    "plt.legend ()\n",
    "\n",
    "fig3 , ax3 = plt.subplots ()\n",
    "for i in range (5) :\n",
    "    ax3.plot ( MatLogErr [i ], label =\"N=%s\" % (( i +1) *20), marker ='o')\n",
    "plt.xticks ( np.arange (0 ,5 , step =1) ,\n",
    "labels = np.array([0.1 ,0.3 ,0.5 ,0.7 ,0.9]) )\n",
    "plt.title (r'Plotting Cross Entropy $CE_ {\\ alpha }$',fontsize ='large ', fontweight ='bold ')\n",
    "plt.xlabel (r'Valori di $\\ alpha$ - Tasso di apprendimento ', fontsize ='large ')\n",
    "plt.ylabel (r'$CE_ {\\ alpha }$', fontsize ='large ')\n",
    "plt.legend ()\n",
    "\n",
    "MatLogErr2 = MatLogErr .T\n",
    "fig4 , ax4 = plt.subplots ()\n",
    "for i in range (5) :\n",
    "    ax4.plot ( MatLogErr2 [ i], label =r'$\\ alpha$ =%.2 g' %((2* i +1) *0.1) , marker ='*')\n",
    "plt.xticks ( np.arange (0 ,5 , step =1) , np.array ([20 ,40 ,60 ,80 ,100]) )\n",
    "plt.title (r'Plotting Cross Entropy $CE_N$ ', fontsize ='large ', fontweight ='bold ')\n",
    "plt.xlabel (r'$N$ - Numero di neuroni nascosti ',fontsize ='large ')\n",
    "plt.ylabel (r'$CE_N$ ', fontsize ='large ')\n",
    "plt.legend ()\n",
    "\n",
    "fig5 , ax5 = plt.subplots ()\n",
    "for i in range (5) :\n",
    "    ax5.plot ( MatriceAccuratezze [i ], label =\"N=%s\" %(( i +1) *20) , marker ='o')\n",
    "plt.xticks ( np.arange (0 ,5 , step =1) ,\n",
    "labels = np.array([0.1 ,0.3 ,0.5 ,0.7 ,0.9]) )\n",
    "plt.title (r'Plotting Accuratezza$_ {\\ alpha }$',fontsize ='large ', fontweight ='bold ')\n",
    "plt.xlabel (r'Valori di $\\ alpha$ - Tasso di apprendimento ', fontsize ='large ')\n",
    "plt.ylabel (r'$Acc_ {\\ alpha }$', fontsize ='large ')\n",
    "plt.legend ()\n",
    "                       \n",
    "MatriceAccuratezze2 = MatriceAccuratezze .T\n",
    "fig6 , ax6 = plt.subplots ()\n",
    "for i in range (5) :\n",
    "    ax6.plot ( MatriceAccuratezze2 [ i], label =r'$\\alpha$ =%.2 g' % ((2* i +1) *0.1) , marker ='*')\n",
    "plt.xticks ( np.arange (0 ,5 , step =1) ,\n",
    "np.array ([20 ,40 ,60 ,80 ,100]) )\n",
    "plt.title (r'Plotting Accuratezza$_N$ ', fontsize ='large ', fontweight ='bold ')\n",
    "plt.xlabel (r'$N$ - Numero di neuroni nascosti ',fontsize ='large ')\n",
    "plt.ylabel (r'$Acc_N$ ', fontsize ='large ')\n",
    "plt.legend ()\n",
    "\n",
    "alpha = alpha *0.1\n",
    "fig7 , ax7 = plt.subplots ()\n",
    "ax7.plot ( Matrice_MSE_TEST [ N1 ][ alpha1 ], marker ='o',color ='r')\n",
    "plt.xticks ( np.arange (0 , NumTest , step =1) , np.arange(20) +1)\n",
    "plt.title (r'Plotting $MSE_ {\\ alpha =%s,N=%s}$' %( alpha,N) , fontsize ='large ',fontweight ='bold ')\n",
    "plt.xlabel (r'Esempio n- esimo del data set ', fontsize='large ')\n",
    "plt.ylabel (r'$MSE$ ', fontsize ='large ')\n",
    "\n",
    " # #### ALTRE VISUALIZZAZIONI ERRORI #####\n",
    "B1 = ListaBM [20]\n",
    "E =[]\n",
    "v_err =[]\n",
    "t_err =[]\n",
    "for k in range (10) :\n",
    "    for i in range ( len ( immagini_training )):\n",
    "        B1.Allenamento ( immagini_training [i ],etichette_training [i ])\n",
    "    E. append ( B1.MatricediConfusione (immagini_training , label_training ))\n",
    "    t_err.append (1 - B1.Accuratezza (E[k ]) )\n",
    "    v_err.append ( B1.MSE )\n",
    "\n",
    "v_err = np.asarray ( v_err )\n",
    "t_err = np.asarray ( t_err )\n",
    "x= np.arange (0 ,10 , step =1)\n",
    "fig8 , ax8 = plt.subplots ()\n",
    "ax8.plot (x , v_err , label =r'$MSE_ {%.2g, %s}$' % (alpha , N) , marker ='o', color ='r')\n",
    "ax8.plot (x , t_err , label =r'$\\ mathrm {acc}_ {%.2g ,%s}$'% ( alpha ,N) , marker ='*')\n",
    "plt.xticks ( np.arange (0 ,10 , step =1) , np.arange (10) +1) \n",
    "titolo =(r'$MSE_ {\\ alpha =%s,N=%s}$ e accuratezza per10 training ses .' %( alpha ,N))\n",
    "plt.title ( titolo , fontsize ='large ', fontweight ='bold')\n",
    "plt.xlabel (r'Sessione n- esima ', fontsize ='large ')\n",
    "plt.ylabel (r'$MSE$ \\ $\\ mathrm { acc}$', fontsize ='large ')\n",
    "plt.legend ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11838c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
