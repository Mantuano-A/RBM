{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5767632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script per analizzare errori / grafici\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib . pyplot as plt\n",
    "from scipy . stats import truncnorm # gaussiana\n",
    "andard troncata\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from termcolor import colored\n",
    "from threading import *\n",
    "import progressbar\n",
    "\n",
    "def sigma (x):\n",
    "    return 1/(1+ np . exp (- x))\n",
    "\n",
    "def dsigmaapprox (x ):\n",
    "    return x *(1 - x)\n",
    "\n",
    " def gaussiana_troncata ( media =0 , varianza =1 , a =0 , b=10) :\n",
    "        return truncnorm ((a - media )/ varianza , (b - media )/varianza ,21 loc = media , scale = varianza )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bd1b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************************\n",
    "# PREPROCESSAMENTO DATI DI TRAINING e TEST\n",
    "dimensione_immagine = 28 # immaginte 28 x 28\n",
    "numero_etichette = 10 # numero delle cifre 0 ,1 ,... ,9\n",
    "pixel_immagine = dimensione_immagine * dimensione_immagine\n",
    "# 784 ~ numero di colonne del test_data + 1 che e' la colonna del label\n",
    "\n",
    "data_path = \"C:/ Users / Matteo Notarnicoa / Desktop / progetto reti / Codici / mnist /\"\n",
    "\n",
    "train_data =[]\n",
    "test_data =[]\n",
    "\n",
    "class CaricamentoTrain ( Thread ):\n",
    "    def run ( self ): \n",
    "        global data_path\n",
    "        global train_data\n",
    "        train_data1 = np.loadtxt ( data_path + \"mnist_train.csv \",delimiter =\",\")\n",
    "        train_data.append( train_data1 )\n",
    "        train_data = train_data[0]\n",
    "    return train_data    \n",
    "\n",
    "class CaricamentoTest ( Thread ):\n",
    "    def run ( self ):\n",
    "        global data_path\n",
    "        global test_data\n",
    "            test_data1 = np.loadtxt ( data_path + \"mnist_test.csv \", delimiter =\",\")\n",
    "        test_data.append( test_data1 )\n",
    "        test_data = test_data[0]\n",
    "    return test_data\n",
    "\n",
    "class BarraTrain ( Thread ):\n",
    "    def run ( self ):\n",
    "        widgets =['[', progressbar.FileTransferSpeed() , ']',progressbar.Bar () ,'(', progressbar.Percentage () , ') ','(', progressbar.ETA () , ')',]\n",
    "        for i in progressbar.progressbar ( range (200) , widgets = widgets , prefix =\"Caricamento dati di training.\\t\"):time.sleep (0.1)\n",
    "\n",
    "class BarraTest ( Thread ):\n",
    "     def run ( self ):\n",
    "        widgets =[ ' [', progressbar.FileTransferSpeed () , '] ',progressbar.Bar () ,' (', progressbar.Percentage () , ') ','(', progressbar.ETA () , ')',]\n",
    "        for i in progressbar.progressbar ( range (100) , widgets = widgets ,prefix =\"Caricamento dati di test.\\t\"):\n",
    "            time.sleep (0.1)\n",
    "\n",
    "t1 = CaricamentoTrain ()\n",
    "t3 = CaricamentoTest ()\n",
    "t2 = BarraTrain ()\n",
    "t4 = BarraTest ()\n",
    "t1.start ()\n",
    "time.sleep (0.01)\n",
    "t2.start ()\n",
    "t1.join ()\n",
    "t2.join ()\n",
    "print (\"\\ nProcesso di caricamento e processamento dei dati di training completato .\\n\", end ='\\n')\n",
    "time.sleep (1)\n",
    "t3.start ()\n",
    "time.sleep (0.01)\n",
    "t4.start ()\n",
    "t3.join ()\n",
    "t4.join ()\n",
    "print (\"\\ nProcesso di caricamento e processamento dei dati di test completato .\\n\", end ='\\n')\n",
    "\n",
    "scala = 0.99 / 255 #i codici per pixel grigi vannoda 0 a 255\n",
    "immagini_training = np.asfarray ( train_data [: , 1:]) *scala + 0.01\n",
    "immagini_test = np.asfarray ( test_data [: , 1:]) *scala + 0.01\n",
    "# prendiamo valori nella matrice tra (0 ,1] -> [0.1 ,1]\n",
    "#e normalizziamo\n",
    "label_training = np.asfarray ( train_data [: , :1])\n",
    "label_test = np.asfarray ( test_data [: , :1])\n",
    "\n",
    "# associamo ad ogni cifra un vettore della basecanonica\n",
    "v= np.arange (10)\n",
    "for etichetta in range (10) :\n",
    "    ei =( v == etichetta ). astype ( np.int )\n",
    " # print (\" Etichetta \", etichetta , \" vettore \", ei)\n",
    "\n",
    "# facciamo la stessa cosa sul vettore dei label memorizzato prima e\n",
    "# togliamo sostiuiamo gli 0 - >0.01\n",
    "tmp = np.arange ( numero_etichette )\n",
    "etichette_training = ( tmp == label_training ).astype( np.float )\n",
    "etichette_test =( tmp == label_test ).astype( np.float )\n",
    "\n",
    "etichette_training [ etichette_training ==0]=0.01\n",
    "etichette_test [ etichette_test ==0]=0.01\n",
    "\n",
    "etichette_training [ etichette_training ==1]=1\n",
    "etichette_test [ etichette_test ==1]=1\n",
    "\n",
    "# Creiamo la classe della rete di richiamo\n",
    "# Definiamo gli estremi di troncamento e i paramentri\n",
    "#di standardizzazione della gaussiana\n",
    "\n",
    "# **********************************\n",
    "# CREAZIONE CLASSE RETE NEURONALE\n",
    "\n",
    "class BM :\n",
    "    def __init__ ( self , nodi_visibili , nodi_nascosti , nodi_output , tasso_apprendimento ) :\n",
    "        self.nodi_visibili = nodi_visibili\n",
    "        self.nodi_nascosti = nodi_nascosti\n",
    "        self.nodi_output = nodi_output\n",
    "        self.tasso_apprendimento = tasso_apprendimento\n",
    "\n",
    "        self.CreaMatricePesi()\n",
    "        self.LogErr =0\n",
    "        self.MSE =0\n",
    "\n",
    "    def CreaMatricePesi ( self ):\n",
    " # inizializziamo la matrice dei pesi usando la distribuzione\n",
    " # normale definita sopra [ cfr.Masters Timothy ]\n",
    "        var1 =1/ np.sqrt ( self.nodi_visibili )\n",
    "        M= gaussiana_troncata (0 ,1 , - var1 , var1 )\n",
    "        self.MatriceInputHidden =M.rvs (( self.nodi_nascosti , self.nodi_visibili ))\n",
    "        var2 =1/ np.sqrt ( self.nodi_nascosti )\n",
    "        M= gaussiana_troncata (0 ,1 , - var2 , var2 )\n",
    "        self.MatriceHiddenOutput = M. rvs (( self.nodi_output , self.nodi_nascosti ))\n",
    "\n",
    " # funzione di training applichiamo usiamo un algoritmo di backpropagation\n",
    " # una discesa del gradiente ( con approssimazionedella derivata ). NO BIAS\n",
    "          \n",
    "    def Allenamento ( self , vettore_input ,vettore_obbiettivo ):\n",
    "        vettore_input = np.array ( vettore_input , ndmin=2).T\n",
    "        vettore_obbiettivo = np.array (vettore_obbiettivo , ndmin =2).T\n",
    " # calcolo le probabilita ' di attivaizione dei neuronivisibili\n",
    "        output_v1 = np.dot( self.MatriceInputHidden , vettore_input )\n",
    "        output_hid = sigma ( output_v1 )\n",
    " # calcolo le probabilita ' di attivazione dei vettorihidden\n",
    "        output_v2 = np.dot ( self.MatriceHiddenOutput ,output_hid )\n",
    "        output = sigma ( output_v2 )\n",
    " # errore strato visibile\n",
    "        errore = vettore_obbiettivo - output # calcolo errore\n",
    " # errore quadratico medio e cross entropy\n",
    "        uno = np.array ([1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1])\n",
    "        self.MSE =(1/10) *((( output - vettore_obbiettivo) **2).sum () )\n",
    "        self.LogErr = -( vettore_obbiettivo * np.log (output ) +( uno - vettore_obbiettivo )* np.log ( uno - output ) ). sum ()\n",
    " # aggiorniamo i pesi MHO\n",
    "        delta = errore * dsigmaapprox ( output )\n",
    "        aggiornamento = self.tasso_apprendimento * np.dot ( delta , output_hid .T)\n",
    "        self.MatriceHiddenOutput += aggiornamento\n",
    " # errore strato nascosto\n",
    "        errore_hidden = np.dot( self.MatriceHiddenOutput .T , errore )\n",
    " # aggiornamnento pesi MIH\n",
    "        delta1 = errore_hidden * dsigmaapprox ( output_hid)\n",
    "        self.MatriceInputHidden += self.tasso_apprendimento * np.dot ( delta1 , vettore_input.T)\n",
    "\n",
    "    def Pensa ( self , vettore_input ):\n",
    "        vettore_input = np.array ( vettore_input ).T\n",
    "        vettore_out = sigma ( np.dot ( self.MatriceInputHidden , vettore_input ) )\n",
    "        vettore_out = sigma ( np.dot ( self.MatriceHiddenOutput , vettore_out ))\n",
    "    return vettore_out\n",
    "\n",
    " # *** FUNZIONI DI ANALLISI E VALIDAZIONE ***\n",
    " # Calcoliamo la matrice di confusione , che da ' unastima della\n",
    " # accuratezza del processo di training ericonoscimento .\n",
    " # Gli elementi sulla diagonale sono il numero deipattern\n",
    " # giustamente riconosciuti e collegati al labelgiusto .\n",
    " # Quelli extradiagonali sono quelli non correttamenteassociati\n",
    "\n",
    "     def MatricediConfusione ( self , dati , etichetta ):\n",
    "        MatConf = np.zeros ((10 ,10) , dtype =int)\n",
    "        for i in range ( len ( dati )) :\n",
    "            risposta = self.Pensa ( dati [i ])\n",
    "            risposta_max = risposta.argmax () # indice del max sulla riga\n",
    "            task = etichetta [i ][0]\n",
    "            MatConf [ risposta_max , int ( task )] += 1\n",
    "        return MatConf\n",
    "\n",
    " # sulla diagonale vi sono il numero delle predizionicorrette\n",
    "\n",
    "     def CalcoloPrecisione ( self , etichetta , MatConf ): \n",
    "        colonna = MatConf [: , etichetta ] # prendo la colonna riferita al label\n",
    "        return MatConf [ etichetta , etichetta ]/ colonna.sum ()\n",
    "          \n",
    "#La precisione e' la percentuale delle previsionipositive\n",
    "# corrette sul totale delle previsioni positive delmodello .\n",
    " # percisione_i := \\ frac {M_{i,i }}{\\ sum_j M_{j,i}}\n",
    " # cioe ' l'elemento i- esimo della diagonale fratto lasomma\n",
    " # degli elementi della colonna i- esima\n",
    "\n",
    "     def CaloloRichiamo ( self , etichetta , MatConf ):\n",
    "        riga = MatConf [ etichetta ,:] # prendo la riga riferita al label\n",
    "        return MatConf [ etichetta , etichetta ]/ riga.sum()\n",
    " \n",
    " #Il richiamo e' la percentuale delle previsionipositive\n",
    " # corrette sul totale delle istanze positive .\n",
    " # richiamo_i := \\ frac {M_{i,i }}{\\ sum_j M_{ij }}\n",
    " # cioe ' e' l'elemento i- esimo della diagonale frattola somma\n",
    " # degli elementi della riga i- esima\n",
    "\n",
    " # Analizziamo i risultati e vediamo quale istanzesono corrette\n",
    " #e quali sono sbagliate , per avere una stima dell ' errore compuito .\n",
    "    def Analisi ( self , dati , etichetta ) :\n",
    "        giusto =0\n",
    "        sbagliato =0\n",
    "        for i in range ( len ( dati )) :\n",
    "            risposta = self.Pensa ( dati [i ]) # processo il pattern i- esimo\n",
    "            risposta_max = risposta.argmax ()\n",
    " # determino l'inidice dell 'elemento di modulo max\n",
    " #e controllo se per caso non sta sulla diagonale\n",
    " #in quel caso sara ' corretto , altrimenti sara 'sbagliato\n",
    "            if risposta_max == etichetta [i ]:\n",
    "                giusto += 1\n",
    "            else :\n",
    "                sbagliato += 1\n",
    "        return giusto , sbagliato\n",
    "\n",
    "     def Accuratezza ( self , MatConf ):\n",
    "        somma_diagonale = MatConf.trace ()\n",
    "        somma_totale = MatConf.sum ()\n",
    "        return somma_diagonale / somma_totale\n",
    " # facciamo il rapporto tra la traccia della matrice ela somma di tutti\n",
    " # gli elementi : infatti sulla diagonale vi sono leistanze correttamente\n",
    " # riconosciute e abbianate .\n",
    "\n",
    " # ***********************************\n",
    " # CREAZIONE CLASSE della RETE\n",
    "Arr_Nodi_Nascosti =20 +20* np.array ( range (5) ) # numerodi neuroni nascosti\n",
    "Arr_Tasso_Apprendimento = 0.1 + 0.2* np.array ( range(5) )\n",
    "\n",
    " # creo una lista di oggetti in cui vi sono le varie\n",
    " # classi BM con diversi valori dei parametri\n",
    "\n",
    "ListaBM =[]\n",
    "for i in range (5) :\n",
    "    for j in range (5) :\n",
    "        MacchinaBoltzmann = BM ( nodi_visibili =pixel_immagine ,nodi_nascosti =Arr_Nodi_Nascosti [ i],nodi_output =10 ,tasso_apprendimento =Arr_Tasso_Apprendimento [j ])ListaBM.append ( MacchinaBoltzmann )\n",
    "\n",
    " # ***************************************\n",
    " # Trasformo la lista in una matrice 5x5\n",
    " # per poterci lavorare sopra\n",
    "          \n",
    "L= ListaBM\n",
    "L= np.asarray ( ListaBM )\n",
    "L= np.split (L ,5 , axis =0)\n",
    "L1 = np.stack (L)\n",
    "\n",
    "# raccolgo i valori delgi errori a processo\n",
    "#di allenamento compleato\n",
    "MatErr = np.zeros ((5 ,5) )\n",
    "MatLogErr = np.zeros ((5 ,5) )\n",
    "\n",
    " # raccolgo i valori delgi errori durante il processo\n",
    "MatIterateMSE =[]\n",
    "MatIterateLogErr =[]\n",
    "\n",
    "AssembleMatriceConfusione =[] # Lista contentente Mat .Conf .\n",
    "MatriceAccuratezze = np.zeros ((5 ,5) ) # Matrice delle accuratezze\n",
    "\n",
    "\n",
    "for i in range (5) :\n",
    "    for j in range (5) :\n",
    "        Macchina = L1 [i ][ j]\n",
    "        for k in range ( len ( immagini_training )):\n",
    "            Macchina.Allenamento ( immagini_training [k], etichette_training [k ])\n",
    "            MatErr [ i ][ j] = Macchina.MSE\n",
    "            MatLogErr [ i ][ j] = Macchina.LogErr\n",
    "            MC = Macchina.MatricediConfusione (immagini_training , label_training )\n",
    "            AssembleMatriceConfusione.append ( MC )\n",
    "            MatriceAccuratezze [ i ][ j] = Macchina.Accuratezza ( MC )\n",
    "\n",
    "AssembleMC = AssembleMatriceConfusione\n",
    "AssembleMC = np.asarray ( AssembleMC )\n",
    "AssembleMC = np.split ( AssembleMC ,5 , axis =0)\n",
    "AssembleMC = np.stack ( AssembleMC )\n",
    "\n",
    " # ##########################\n",
    " # TEST RETE\n",
    "NumTest =20\n",
    "Matrice_MSE_TEST =[]\n",
    "\n",
    "for i in range (5) :\n",
    "    for j in range (5) :\n",
    "        BM = L1 [ i ][ j]\n",
    "        Vett_MSE_Test =[]\n",
    "        for k in range ( NumTest ): # faccio i primi 50 test per ogni par .\n",
    "            out = BM.Pensa ( immagini_test [k ])\n",
    "            err = (1/10) *((( out - etichette_test [ k ])**2).sum () )\n",
    "            Vett_MSE_Test.append ( err ) # vett 1 xrange\n",
    "            Matrice_MSE_TEST.append ( np.asarray (\n",
    "    Vett_MSE_Test , dtype = float ))\n",
    "\n",
    "Matrice_MSE_TEST = np.asarray ( Matrice_MSE_TEST )\n",
    "Matrice_MSE_TEST = np.split ( Matrice_MSE_TEST ,5 , axis =0)\n",
    "Matrice_MSE_TEST = np.stack ( Matrice_MSE_TEST )\n",
    "\n",
    "alpha =int( input (\" Scegli un valore per il tasso diapprendimento \\ ntra {1 ,3 ,5 ,7 ,9}: \"))\n",
    "N= int ( input (\" Scegli il numero dei neuroni nascosti \\ntra {20 ,40 ,60 ,80 ,100}: \"))\n",
    "\n",
    "if alpha == 1:\n",
    "    alpha1 = 0\n",
    "elif alpha == 3:\n",
    "    alpha1 = 1\n",
    "elif alpha == 5:\n",
    "    alpha1 = 2\n",
    "elif alpha == 7:\n",
    "    alpha1 = 3\n",
    "elif alpha == 9:\n",
    "    alpha1 = 4\n",
    "\n",
    "if N == 20:\n",
    "    N1 = 0\n",
    "                    \n",
    "elif N == 40:\n",
    "    N1 = 1\n",
    "elif N == 60:\n",
    "    N1 = 2\n",
    "elif N == 80:\n",
    "    N1 = 3\n",
    "elif N == 100:\n",
    "    N1 = 4\n",
    "\n",
    "# ######################################\n",
    "# VISUALIZZAZIONE DEI DATI CALCOLATI\n",
    "fig1 , ax1 = plt.subplots ()\n",
    "for i in range (5) :\n",
    "    ax1.plot ( MatErr [i], label =\"N=%s\" % (( i +1) *20) ,marker ='o')\n",
    "plt.xticks ( np.arange (0 ,5 , step =1) ,\n",
    "labels = np.array ([0.1 ,0.3 ,0.5 ,0.7 ,0.9]) )\n",
    "plt.title (r'Plotting $MSE_ {\\ alpha }$', fontsize ='large ', fontweight ='bold ')\n",
    "plt.xlabel (r'Valori di $\\ alpha$ - Tasso di apprendimento ', fontsize ='large ')\n",
    "plt.ylabel (r'$MSE_ {\\ alpha }$', fontsize ='large ')\n",
    "plt.legend ()\n",
    "\n",
    "MatErr2 = MatErr .T\n",
    "fig2 , ax2 = plt.subplots ()\n",
    "for i in range (5) :\n",
    "ax2.plot ( MatErr2 [i], label =r'$\\ alpha$ =%.2 g' % ((2* i +1) *0.1) , marker ='*')\n",
    "plt.xticks ( np.arange (0 ,5 , step =1) ,\n",
    "labels = np.array ([20 ,40 ,60 ,80 ,100]) )\n",
    "plt.title (r'Plotting $MSE_N$ ', fontsize ='large ',fontweight ='bold ')\n",
    "plt.xlabel (r'$N$ - Numero di neuroni nascosti ', fontsize ='large ')\n",
    "plt.ylabel (r'$MSE_N$ ', fontsize ='large ')\n",
    "plt.legend ()\n",
    "\n",
    "fig3 , ax3 = plt.subplots ()\n",
    "for i in range (5) :\n",
    "    ax3.plot ( MatLogErr [i ], label =\"N=%s\" % (( i +1) *20), marker ='o')\n",
    "plt.xticks ( np.arange (0 ,5 , step =1) ,\n",
    "labels = np.array([0.1 ,0.3 ,0.5 ,0.7 ,0.9]) )\n",
    "plt.title (r'Plotting Cross Entropy $CE_ {\\ alpha }$',fontsize ='large ', fontweight ='bold ')\n",
    "plt.xlabel (r'Valori di $\\ alpha$ - Tasso di apprendimento ', fontsize ='large ')\n",
    "plt.ylabel (r'$CE_ {\\ alpha }$', fontsize ='large ')\n",
    "plt.legend ()\n",
    "\n",
    "MatLogErr2 = MatLogErr .T\n",
    "fig4 , ax4 = plt.subplots ()\n",
    "for i in range (5) :\n",
    "    ax4.plot ( MatLogErr2 [ i], label =r'$\\ alpha$ =%.2 g' %((2* i +1) *0.1) , marker ='*')\n",
    "plt.xticks ( np.arange (0 ,5 , step =1) , np.array ([20 ,40 ,60 ,80 ,100]) )\n",
    "plt.title (r'Plotting Cross Entropy $CE_N$ ', fontsize ='large ', fontweight ='bold ')\n",
    "plt.xlabel (r'$N$ - Numero di neuroni nascosti ',fontsize ='large ')\n",
    "plt.ylabel (r'$CE_N$ ', fontsize ='large ')\n",
    "plt.legend ()\n",
    "\n",
    "fig5 , ax5 = plt.subplots ()\n",
    "for i in range (5) :\n",
    "    ax5.plot ( MatriceAccuratezze [i ], label =\"N=%s\" %(( i +1) *20) , marker ='o')\n",
    "plt.xticks ( np.arange (0 ,5 , step =1) ,\n",
    "labels = np.array([0.1 ,0.3 ,0.5 ,0.7 ,0.9]) )\n",
    "plt.title (r'Plotting Accuratezza$_ {\\ alpha }$',fontsize ='large ', fontweight ='bold ')\n",
    "plt.xlabel (r'Valori di $\\ alpha$ - Tasso di apprendimento ', fontsize ='large ')\n",
    "plt.ylabel (r'$Acc_ {\\ alpha }$', fontsize ='large ')\n",
    "plt.legend ()\n",
    "                       \n",
    "MatriceAccuratezze2 = MatriceAccuratezze .T\n",
    "fig6 , ax6 = plt.subplots ()\n",
    "for i in range (5) :\n",
    "    ax6.plot ( MatriceAccuratezze2 [ i], label =r'$\\alpha$ =%.2 g' % ((2* i +1) *0.1) , marker ='*')\n",
    "plt.xticks ( np.arange (0 ,5 , step =1) ,\n",
    "np.array ([20 ,40 ,60 ,80 ,100]) )\n",
    "plt.title (r'Plotting Accuratezza$_N$ ', fontsize ='large ', fontweight ='bold ')\n",
    "plt.xlabel (r'$N$ - Numero di neuroni nascosti ',fontsize ='large ')\n",
    "plt.ylabel (r'$Acc_N$ ', fontsize ='large ')\n",
    "plt.legend ()\n",
    "\n",
    "alpha = alpha *0.1\n",
    "fig7 , ax7 = plt.subplots ()\n",
    "ax7.plot ( Matrice_MSE_TEST [ N1 ][ alpha1 ], marker ='o',color ='r')\n",
    "plt.xticks ( np.arange (0 , NumTest , step =1) , np.arange(20) +1)\n",
    "plt.title (r'Plotting $MSE_ {\\ alpha =%s,N=%s}$' %( alpha,N) , fontsize ='large ',fontweight ='bold ')\n",
    "plt.xlabel (r'Esempio n- esimo del data set ', fontsize='large ')\n",
    "plt.ylabel (r'$MSE$ ', fontsize ='large ')\n",
    "\n",
    " # #### ALTRE VISUALIZZAZIONI ERRORI #####\n",
    "B1 = ListaBM [20]\n",
    "E =[]\n",
    "v_err =[]\n",
    "t_err =[]\n",
    "for k in range (10) :\n",
    "    for i in range ( len ( immagini_training )):\n",
    "        B1.Allenamento ( immagini_training [i ],etichette_training [i ])\n",
    "    E. append ( B1.MatricediConfusione (immagini_training , label_training ))\n",
    "    t_err.append (1 - B1.Accuratezza (E[k ]) )\n",
    "    v_err.append ( B1.MSE )\n",
    "\n",
    "v_err = np.asarray ( v_err )\n",
    "t_err = np.asarray ( t_err )\n",
    "x= np.arange (0 ,10 , step =1)\n",
    "fig8 , ax8 = plt.subplots ()\n",
    "ax8.plot (x , v_err , label =r'$MSE_ {%.2g, %s}$' % (alpha , N) , marker ='o', color ='r')\n",
    "ax8.plot (x , t_err , label =r'$\\ mathrm {acc}_ {%.2g ,%s}$'% ( alpha ,N) , marker ='*')\n",
    "plt.xticks ( np.arange (0 ,10 , step =1) , np.arange (10) +1) \n",
    "titolo =(r'$MSE_ {\\ alpha =%s,N=%s}$ e accuratezza per10 training ses .' %( alpha ,N))\n",
    "plt.title ( titolo , fontsize ='large ', fontweight ='bold')\n",
    "plt.xlabel (r'Sessione n- esima ', fontsize ='large ')\n",
    "plt.ylabel (r'$MSE$ \\ $\\ mathrm { acc}$', fontsize ='large ')\n",
    "plt.legend ()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
